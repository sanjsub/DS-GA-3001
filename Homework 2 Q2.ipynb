{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "noble-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import brier_score_loss, make_scorer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, TimeSeriesSplit, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "small-baptist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Y</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>home_xG</th>\n",
       "      <th>away_xG</th>\n",
       "      <th>GameID</th>\n",
       "      <th>HomeWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPL</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.554110</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPL</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Everton</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.278300</td>\n",
       "      <td>0.613273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPL</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.166350</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPL</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>QPR</td>\n",
       "      <td>Hull</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.900670</td>\n",
       "      <td>1.117570</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPL</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div        Date   Y    HomeTeam        AwayTeam  FTHG  FTAG  HTHG  HTAG  \\\n",
       "0  EPL  2014-08-16  14     Arsenal  Crystal Palace     2     1     1     1   \n",
       "1  EPL  2014-08-16  14   Leicester         Everton     2     2     1     2   \n",
       "2  EPL  2014-08-16  14  Man United         Swansea     1     2     0     1   \n",
       "3  EPL  2014-08-16  14         QPR            Hull     0     1     0     0   \n",
       "4  EPL  2014-08-16  14       Stoke     Aston Villa     0     1     0     0   \n",
       "\n",
       "   HS  AS  HST  AST   home_xG   away_xG  GameID  HomeWin  \n",
       "0  14   4    6    2  1.554110  0.158151       0        1  \n",
       "1  11  13    3    3  1.278300  0.613273       1        0  \n",
       "2  14   5    5    4  1.166350  0.278076       2        0  \n",
       "3  19  11    6    4  1.900670  1.117570       3        0  \n",
       "4  12   7    2    2  0.423368  0.909774       4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('soccer18.csv')\n",
    "data['GameID'] = data.index\n",
    "data['HomeWin'] = 1*(data['FTHG'] > data['FTAG'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deadly-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each game into two rows and identifying home team\n",
    "datamelt = pd.melt(data, \n",
    "                   id_vars = ['GameID','Date','Div','Y','FTHG','FTAG','HTHG','HTAG','HS','AS','HST','AST','home_xG','away_xG',\n",
    "                              'HomeWin'], value_vars = ['HomeTeam','AwayTeam'], var_name = 'HA', value_name = 'Team')\n",
    "datamelt['isHome'] = 1*(datamelt['HA'] == 'HomeTeam') - 1*(datamelt['HA'] == 'AwayTeam')\n",
    "datamelt['isHome2'] = 1*(datamelt['HA'] == 'HomeTeam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "regional-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding differentials for each stat\n",
    "datamelt['GDiff'] = (datamelt['FTHG'] - datamelt['FTAG'])*datamelt['isHome']\n",
    "datamelt['SDiff'] = (datamelt['HS'] - datamelt['AS'])*datamelt['isHome']\n",
    "datamelt['STDiff'] = (datamelt['HST'] - datamelt['AST'])*datamelt['isHome']\n",
    "datamelt['xGDiff'] = (datamelt['home_xG'] - datamelt['away_xG'])*datamelt['isHome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "expired-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamelt = datamelt.sort_values(['Date','GameID'])\n",
    "\n",
    "# Using ewm to compute rolling weighted averages for each stat to capture recent trends/momentum\n",
    "datamelt['AvgGDiff'] = datamelt.groupby('Team')['GDiff'].transform(lambda x : x.ewm(halflife = 15).mean().shift(1, fill_value = 0))\n",
    "datamelt['AvgSDiff'] = datamelt.groupby('Team')['SDiff'].transform(lambda x : x.ewm(halflife = 15).mean().shift(1, fill_value = 0))\n",
    "datamelt['AvgSTDiff'] = datamelt.groupby('Team')['STDiff'].transform(lambda x : x.ewm(halflife = 15).mean().shift(1, fill_value = 0))\n",
    "datamelt['AvgxGDiff'] = datamelt.groupby('Team')['xGDiff'].transform(lambda x : x.ewm(halflife = 15).mean().shift(1, fill_value = 0))\n",
    "\n",
    "# Games played at home or away\n",
    "datamelt['GamesPlayedHome'] = datamelt.groupby('Team')['isHome2'].apply(lambda x: x.shift().fillna(0).cumsum())\n",
    "datamelt['GamesPlayedAway'] = datamelt.groupby('Team')['isHome2'].apply(lambda x: x.sub(1).abs().shift().fillna(0).cumsum())\n",
    "\n",
    "# Calculating win percentage at home and away for each team\n",
    "datamelt['WinAtHome'] = datamelt['HomeWin'] * (datamelt['HA'] == 'HomeTeam')\n",
    "datamelt['WinPctAtHome'] = datamelt.groupby('Team')['WinsAtHome'].transform(lambda x : x.cumsum().shift(1, fill_value = 0))/datamelt['GamesPlayedHome']\n",
    "datamelt['WinPctAtHome'] = datamelt.groupby('Team')['WinPctAtHome'].transform(lambda x : x.ewm(halflife = 10).mean())\n",
    "\n",
    "datamelt['WinAway'] = datamelt['HomeWin'].replace({0: 1, 1: 0}) * (datamelt['HA'] == 'AwayTeam')\n",
    "datamelt['WinPctAway'] = datamelt.groupby('Team')['WinAway'].transform(lambda x : x.cumsum().shift(1, fill_value = 0))/datamelt['GamesPlayedAway']\n",
    "datamelt['WinPctAway'] = datamelt.groupby('Team')['WinPctAway'].transform(lambda x : x.ewm(halflife = 10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "regular-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting data back into original format and taking differences between home and away differentials\n",
    "pivotdata = datamelt.pivot_table(index=['GameID','Y','Date','Div'], columns=['HA'], \n",
    "                                 values=['AvgGDiff','AvgSDiff','AvgSTDiff','AvgxGDiff','Team','WinPctAtHome', 'WinPctAway'], \n",
    "                                 aggfunc='first')\n",
    "pivotdata.columns = ['AwayAvgGDiff','HomeAvgGDiff','AwayAvgSDiff','HomeAvgSDiff','AwayAvgSTDiff','HomeAvgSTDiff',\n",
    "                     'AwayAvgxGDiff','HomeAvgxGDiff','AwayTeam','HomeTeam','AwayWinPctAtHome','HomeWinPctAtHome',\n",
    "                     'AwayWinPctAway', 'HomeWinPctAway']\n",
    "pivotdata.reset_index(inplace = True)\n",
    "pivotdata['AvgGDiffDiff'] = pivotdata['HomeAvgGDiff'] - pivotdata['AwayAvgGDiff']\n",
    "pivotdata['AvgSDiffDiff'] = pivotdata['HomeAvgSDiff'] - pivotdata['AwayAvgSDiff']\n",
    "pivotdata['AvgSTDiffDiff'] = pivotdata['HomeAvgSTDiff'] - pivotdata['AwayAvgSTDiff']\n",
    "pivotdata['AvgxGDiffDiff'] = pivotdata['HomeAvgxGDiff'] - pivotdata['AwayAvgxGDiff']\n",
    "pivotdata['WinPctDiff'] = pivotdata['HomeWinPctAtHome'] - pivotdata['AwayWinPctAway']\n",
    "\n",
    "pivotdata = pivotdata.sort_values(['Date','GameID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "complicated-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering/cleaning dataframe for use in model\n",
    "datamaster = data.merge(pivotdata[['Date','GameID','AvgGDiffDiff','AvgSDiffDiff',\n",
    "                                   'AvgSTDiffDiff','AvgxGDiffDiff','HomeWinPctAtHome','AwayWinPctAway']], \n",
    "                        on = ['Date','GameID'], how = 'inner').sort_values(['Date','GameID'])\n",
    "datamaster.drop(['GameID','Date','Div','FTHG','FTAG','HTHG','HTAG','HS','AS','HST','AST','home_xG','away_xG'], \n",
    "                axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "meaningful-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = datamaster[datamaster['Y'] < 18].drop(['Y','HomeWin','HomeTeam','AwayTeam'], axis = 1).fillna(0)\n",
    "y_train = datamaster[datamaster['Y'] < 18]['HomeWin']\n",
    "x_test = datamaster[datamaster['Y'] == 18].drop(['Y','HomeWin','HomeTeam','AwayTeam'], axis = 1).fillna(0)\n",
    "y_test = datamaster[datamaster['Y'] == 18]['HomeWin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "linear-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "tscv = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "#Build a list of steps, where the first is StandardScaler and the last is RandomForest\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression(solver = 'liblinear'))]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#Now set up the parameter grid\n",
    "parameters_scaler = dict(lr__C = [10**i for i in range(-3, 3)],\n",
    "                         lr__penalty = ['l1', 'l2'],\n",
    "                         lr__max_iter = [100, 1000, 10000])\n",
    "\n",
    "#Now run a grid search\n",
    "lr_grid_search_scaler = GridSearchCV(pipeline, param_grid = parameters_scaler, cv = tscv, scoring = 'neg_brier_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "french-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fit model to training data\n",
    "lr_grid_search_scaler.fit(x_train, y_train)\n",
    "\n",
    "proba = lr_grid_search_scaler.predict_proba(x_test)\n",
    "brierscore = brier_score_loss(y_test, proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "instrumental-potato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21347867563728137"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brierscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "included-threat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1, max_iter=1000, penalty='l1',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search_scaler.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cloudy-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "tscv = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "#Create a set of steps. All but the last step is a transformer (something that processes data). \n",
    "#Build a list of steps, where the first is StandardScaler and the last is RandomForest\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('svc', SVC(probability = True))]\n",
    "\n",
    "#Now set up the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "BrierLoss = make_scorer(brier_score_loss, greater_is_better = False, needs_proba = True)\n",
    "\n",
    "#Now set up the parameter grid\n",
    "parameters_scaler = dict(svc__C = [10**i for i in range(-3, 3)],\n",
    "                         svc__kernel = ['linear', 'sigmoid', 'rbf'],\n",
    "                         svc__gamma = [1,0.1,0.01,0.001])\n",
    "\n",
    "#Now run a grid search\n",
    "svc_grid_search_scaler = GridSearchCV(pipeline, param_grid = parameters_scaler, cv = tscv, scoring = BrierLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "simple-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fit model to training data\n",
    "svc_grid_search_scaler.fit(x_train, y_train)\n",
    "\n",
    "proba = svc_grid_search_scaler.predict_proba(x_test)\n",
    "brierscore = brier_score_loss(y_test, proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "narrow-draft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21350713986911402"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brierscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-visitor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
